{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9L dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odGi7X0q8j6U",
        "outputId": "1a7796a5-d3c2-478b-d5ca-6879e791776a"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "if 'google.colab' in sys.modules:\r\n",
        "  %tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf.random.set_seed(1234)\r\n",
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "!pip install tensorflow-datasets==1.2.0\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "import os\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "from time import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(\"Tensorflow version {}\".format(tf.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-datasets==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.25.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.15.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (5.4.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==1.2.0) (20.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==1.2.0) (1.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-datasets==1.2.0) (50.3.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==1.2.0) (2020.12.5)\n",
            "Installing collected packages: tensorflow-datasets\n",
            "  Found existing installation: tensorflow-datasets 4.0.1\n",
            "    Uninstalling tensorflow-datasets-4.0.1:\n",
            "      Successfully uninstalled tensorflow-datasets-4.0.1\n",
            "Successfully installed tensorflow-datasets-1.2.0\n",
            "Tensorflow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5fY13Mm8uGb",
        "outputId": "78fd1333-8a33-4aa7-cd6c-865dd5d26e5f"
      },
      "source": [
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU ['10.67.114.26:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.114.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.114.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c8S4Vglag0B"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXq-ML7Z9ZY-"
      },
      "source": [
        "# Maximum sentence length\r\n",
        "MAX_LENGTH = 60\r\n",
        "\r\n",
        "# Maximum number of samples to preprocess\r\n",
        "MAX_SAMPLES = 50000\r\n",
        "\r\n",
        "# For tf.data.Dataset\r\n",
        "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\r\n",
        "BUFFER_SIZE = 30000\r\n",
        "\r\n",
        "# For Transformer\r\n",
        "NUM_LAYERS = 2\r\n",
        "D_MODEL = 512\r\n",
        "NUM_HEADS = 16\r\n",
        "UNITS = 512\r\n",
        "DROPOUT = 0.1\r\n",
        "\r\n",
        "EPOCHS = 20"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dvbCAgUxMIH"
      },
      "source": [
        "# Code to read csv file into Colaboratory:\r\n",
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "# Authenticate and create the PyDrive client.\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kJ999Wfx-L_"
      },
      "source": [
        "id = '1rrqbtyxQTTbuONa3_ORMmR6e8YIedOuD' "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLXMhPzcyVs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774253d6-6207-493e-9a15-5beaa4001b11"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':id}) \r\n",
        "downloaded.GetContentFile('9L_dataset.json')  \r\n",
        "df3 = pd.read_json('9L_dataset.json')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 42, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHqbwobDyjtf",
        "outputId": "80cdd148-a68e-4249-970b-5967730f4eb8"
      },
      "source": [
        "print(df3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 question                                             answer\n",
            "0       About how long before seeing herpes lesions do...  NO easy answer. You are the most contagious wh...\n",
            "1                      Acute HIV rash lasts for how long?  Not all patients have acute HIV symptoms. Acut...\n",
            "2       After being exposed, how long does it take for...  Hpv. Hpv is very contagious and there is no la...\n",
            "3       After contracting poison ivy, how long does it...  It is not contagious. I agree w dr. Chiu. Urus...\n",
            "4       After taking tobramycin how long am I still co...  A full course. Of antibiotics is the only way ...\n",
            "...                                                   ...                                                ...\n",
            "943763  What diagnosis would require platelet and ster...  Thrombocytopenia. Thrombocytopenia is low  pla...\n",
            "943764          What is the treatment  for prolactinomas?  Two possible treatments -- surgery or medicati...\n",
            "943765              What is the treatment for hypetension  Not an easy question. There are many forms of ...\n",
            "943766                What is the treatment for gangrene?  May need to be removed, cut out, amputated to ...\n",
            "943767       Does gabitril (tiagabine) cause weight gain?  Among the many side effects of the drug is inc...\n",
            "\n",
            "[943768 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "uQLAyfMpzMcg",
        "outputId": "46dc70ba-1e31-4b11-a935-cafa8d54b352"
      },
      "source": [
        "df3"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>About how long before seeing herpes lesions do...</td>\n",
              "      <td>NO easy answer. You are the most contagious wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Acute HIV rash lasts for how long?</td>\n",
              "      <td>Not all patients have acute HIV symptoms. Acut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>After being exposed, how long does it take for...</td>\n",
              "      <td>Hpv. Hpv is very contagious and there is no la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>After contracting poison ivy, how long does it...</td>\n",
              "      <td>It is not contagious. I agree w dr. Chiu. Urus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>After taking tobramycin how long am I still co...</td>\n",
              "      <td>A full course. Of antibiotics is the only way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943763</th>\n",
              "      <td>What diagnosis would require platelet and ster...</td>\n",
              "      <td>Thrombocytopenia. Thrombocytopenia is low  pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943764</th>\n",
              "      <td>What is the treatment  for prolactinomas?</td>\n",
              "      <td>Two possible treatments -- surgery or medicati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943765</th>\n",
              "      <td>What is the treatment for hypetension</td>\n",
              "      <td>Not an easy question. There are many forms of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943766</th>\n",
              "      <td>What is the treatment for gangrene?</td>\n",
              "      <td>May need to be removed, cut out, amputated to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943767</th>\n",
              "      <td>Does gabitril (tiagabine) cause weight gain?</td>\n",
              "      <td>Among the many side effects of the drug is inc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943768 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question                                             answer\n",
              "0       About how long before seeing herpes lesions do...  NO easy answer. You are the most contagious wh...\n",
              "1                      Acute HIV rash lasts for how long?  Not all patients have acute HIV symptoms. Acut...\n",
              "2       After being exposed, how long does it take for...  Hpv. Hpv is very contagious and there is no la...\n",
              "3       After contracting poison ivy, how long does it...  It is not contagious. I agree w dr. Chiu. Urus...\n",
              "4       After taking tobramycin how long am I still co...  A full course. Of antibiotics is the only way ...\n",
              "...                                                   ...                                                ...\n",
              "943763  What diagnosis would require platelet and ster...  Thrombocytopenia. Thrombocytopenia is low  pla...\n",
              "943764          What is the treatment  for prolactinomas?  Two possible treatments -- surgery or medicati...\n",
              "943765              What is the treatment for hypetension  Not an easy question. There are many forms of ...\n",
              "943766                What is the treatment for gangrene?  May need to be removed, cut out, amputated to ...\n",
              "943767       Does gabitril (tiagabine) cause weight gain?  Among the many side effects of the drug is inc...\n",
              "\n",
              "[943768 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ba0H3quRfI"
      },
      "source": [
        "import re\r\n",
        "def preprocess_sentence(sentence):\r\n",
        "  sentence = sentence.lower().strip()\r\n",
        "  # creating a space between a word and the punctuation following it\r\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\r\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\r\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\r\n",
        "  # removing contractions\r\n",
        "  sentence = re.sub(r\"i'm\", \"i am\", sentence)\r\n",
        "  sentence = re.sub(r\"he's\", \"he is\", sentence)\r\n",
        "  sentence = re.sub(r\"she's\", \"she is\", sentence)\r\n",
        "  sentence = re.sub(r\"it's\", \"it is\", sentence)\r\n",
        "  sentence = re.sub(r\"that's\", \"that is\", sentence)\r\n",
        "  sentence = re.sub(r\"what's\", \"that is\", sentence)\r\n",
        "  sentence = re.sub(r\"where's\", \"where is\", sentence)\r\n",
        "  sentence = re.sub(r\"how's\", \"how is\", sentence)\r\n",
        "  sentence = re.sub(r\"\\'ll\", \" will\", sentence)\r\n",
        "  sentence = re.sub(r\"\\'ve\", \" have\", sentence)\r\n",
        "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\r\n",
        "  sentence = re.sub(r\"\\'d\", \" would\", sentence)\r\n",
        "  sentence = re.sub(r\"\\'re\", \" are\", sentence)\r\n",
        "  sentence = re.sub(r\"won't\", \"will not\", sentence)\r\n",
        "  sentence = re.sub(r\"can't\", \"cannot\", sentence)\r\n",
        "  sentence = re.sub(r\"n't\", \" not\", sentence)\r\n",
        "  sentence = re.sub(r\"n'\", \"ng\", sentence)\r\n",
        "  sentence = re.sub(r\"'bout\", \"about\", sentence)\r\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\r\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,0-9 %]+\", \" \", sentence)\r\n",
        "  sentence = sentence.strip()\r\n",
        "  return sentence"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z378PQY-Cpnj"
      },
      "source": [
        "questions = []\r\n",
        "for i in df3.question:\r\n",
        "  i = str(i)\r\n",
        "  #i = preprocess_sentence(i)\r\n",
        "  questions.append(i)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPKdwhmIMEF6"
      },
      "source": [
        "answers = []\r\n",
        "for i in df3.answer:\r\n",
        "  i = str(i)\r\n",
        "  #strings = i[(i.find(\"'answer'\")) + 11:i.find(\"}\")-1]\r\n",
        "  #strings = preprocess_sentence(i)\r\n",
        "  answers.append(i)\r\n",
        "\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLCjH1tUQAh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173544c5-c125-4604-de93-669c1674a3c6"
      },
      "source": [
        "print(questions[201])\r\n",
        "print(\"\\n\")\r\n",
        "print(answers[201])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Can you catch shingles from other people?\n",
            "\n",
            "\n",
            "Shingles represents reactivation of VZV or chicken pox virus in someone who has already been infected. If you have never been infected by VZV before or are not vaccinated for it, and you are exposed to someone with shingles you can easily end up with chicken pox.  Then, later on in life, the chicken pox may reactivate in you and give you shingles.....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZOzoX6Yv7sF",
        "outputId": "4bd6cb3f-e57a-4757-89b2-96c0d326ddbc"
      },
      "source": [
        "print(df3.question[200])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Can you catch pnemoia from someone else?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "svO04M3Vwm8H",
        "outputId": "7cf5fa82-d23a-431b-9f21-64058f47fdc0"
      },
      "source": [
        "preprocess_sentence('is 10,000 years old.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'is 10 , 000 years old .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOawHG1axUi8",
        "outputId": "872978c3-8b58-4e96-b194-a6dc8538c2c9"
      },
      "source": [
        "print(df3.answer[200])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NOT USUALLY, but.... Depends on type :  e.g. Walking pneumonia (mycoplasma) is mildy contagious and is now recognized as one of the most common causes of community-acquired pneumonia. Most common ages 5-20 but can occur any age. However only 5-10% of infected patients actually develop pneumonia. Most people with viral or bacterial pneumonia don't pass it to the people around them.  Here's a tip: avoid people w/cough.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blb-3gmoyIs2"
      },
      "source": [
        "# Build tokenizer using tfds for both questions and answers\r\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\r\n",
        "    questions + answers, target_vocab_size=20000)\r\n",
        "\r\n",
        "# Define start and end token to indicate the start and end of a sentence\r\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\r\n",
        "\r\n",
        "# Vocabulary size plus start and end token\r\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxVXQE9m-HeB",
        "outputId": "a42714a9-d449-4674-e1ee-06549b898630"
      },
      "source": [
        "print('Tokenized sample question: {}'.format(tokenizer.encode(questions[20])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenized sample question: [279, 113, 110, 73, 3, 1976, 8, 3768, 7, 5, 340, 2995, 19686]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDmJ7uQBCwe-"
      },
      "source": [
        "# Tokenize, filter and pad sentences\r\n",
        "def tokenize_and_filter(inputs, outputs):\r\n",
        "  tokenized_inputs, tokenized_outputs = [], []\r\n",
        "  \r\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\r\n",
        "    # tokenize sentence\r\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\r\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\r\n",
        "    # check tokenized sentence max length\r\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\r\n",
        "      tokenized_inputs.append(sentence1)\r\n",
        "      tokenized_outputs.append(sentence2)\r\n",
        "  \r\n",
        "  # pad tokenized sentences\r\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\r\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\r\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\r\n",
        "  \r\n",
        "  return tokenized_inputs, tokenized_outputs\r\n",
        "\r\n",
        "\r\n",
        "questions, answers = tokenize_and_filter(questions, answers)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN5bgFFNC6N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5052c428-bf81-447b-a03a-c0087b2f10a7"
      },
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\r\n",
        "print('Number of samples: {}'.format(len(questions)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 19881\n",
            "Number of samples: 553985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h8rfvrzEaKw"
      },
      "source": [
        "# decoder inputs use the previous target as input\r\n",
        "# remove START_TOKEN from targets\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\r\n",
        "    {\r\n",
        "        'inputs': questions,\r\n",
        "        'dec_inputs': answers[:, :-1]\r\n",
        "    },\r\n",
        "    {\r\n",
        "        'outputs': answers[:, 1:]\r\n",
        "    },\r\n",
        "))\r\n",
        "\r\n",
        "dataset = dataset.cache()\r\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE)\r\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLtxJFgr_Ar6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed0ef18-324b-437f-f05e-de43dc19804b"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ({inputs: (None, 60), dec_inputs: (None, 59)}, {outputs: (None, 59)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHpvoe2Kbp_"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\r\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\r\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\r\n",
        "\r\n",
        "  # scale matmul_qk\r\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\r\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\r\n",
        "\r\n",
        "  # add the mask to zero out padding tokens\r\n",
        "  if mask is not None:\r\n",
        "    logits += (mask * -1e9)\r\n",
        "\r\n",
        "  # softmax is normalized on the last axis (seq_len_k)\r\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\r\n",
        "\r\n",
        "  output = tf.matmul(attention_weights, value)\r\n",
        "\r\n",
        "  return output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQBdSuXfLNgS"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\r\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\r\n",
        "    self.num_heads = num_heads\r\n",
        "    self.d_model = d_model\r\n",
        "\r\n",
        "    assert d_model % self.num_heads == 0\r\n",
        "\r\n",
        "    self.depth = d_model // self.num_heads\r\n",
        "\r\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "\r\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\r\n",
        "  \r\n",
        "  def get_config(self):\r\n",
        "        config = super(MultiHeadAttention,self).get_config()\r\n",
        "        config.update({\r\n",
        "            'num_heads':self.num_heads,\r\n",
        "            'd_model':self.d_model,\r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "  def split_heads(self, inputs, batch_size):\r\n",
        "    inputs = tf.keras.layers.Lambda(lambda inputs:tf.reshape(\r\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth)))(inputs)\r\n",
        "    return tf.keras.layers.Lambda(lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3]))(inputs)\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\r\n",
        "        'value'], inputs['mask']\r\n",
        "    batch_size = tf.shape(query)[0]\r\n",
        "\r\n",
        "    # linear layers\r\n",
        "    query = self.query_dense(query)\r\n",
        "    key = self.key_dense(key)\r\n",
        "    value = self.value_dense(value)\r\n",
        "\r\n",
        "    # split heads\r\n",
        "    query = self.split_heads(query, batch_size)\r\n",
        "    key = self.split_heads(key, batch_size)\r\n",
        "    value = self.split_heads(value, batch_size)\r\n",
        "\r\n",
        "    # scaled dot-product attention\r\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\r\n",
        "    scaled_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.transpose(\r\n",
        "        scaled_attention, perm=[0, 2, 1, 3]))(scaled_attention)\r\n",
        "\r\n",
        "    # concatenation of heads\r\n",
        "    concat_attention = tf.keras.layers.Lambda(lambda scaled_attention: tf.reshape(scaled_attention,\r\n",
        "                                  (batch_size, -1, self.d_model)))(scaled_attention)\r\n",
        "\r\n",
        "    # final linear layer\r\n",
        "    outputs = self.dense(concat_attention)\r\n",
        "\r\n",
        "    return outputs    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SWu3kXZMqD6"
      },
      "source": [
        "def create_padding_mask(x):\r\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\r\n",
        "  # (batch_size, 1, 1, sequence length)\r\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzjOFjJHM9GW",
        "outputId": "f7aeb1e6-2f25-4f94-8658-720f3419de9c"
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWbiziSGNAqV"
      },
      "source": [
        "def create_look_ahead_mask(x):\r\n",
        "  seq_len = tf.shape(x)[1]\r\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\r\n",
        "  padding_mask = create_padding_mask(x)\r\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBcrLfhWNHxb",
        "outputId": "76d39b55-ac99-4973-9caf-c8fc6d56db41"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abftCf2VNJ8W"
      },
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "  def __init__(self, position, d_model):\r\n",
        "    super(PositionalEncoding, self).__init__()\r\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\r\n",
        "  \r\n",
        "  def get_config(self):\r\n",
        "\r\n",
        "        config = super(PositionalEncoding, self).get_config()\r\n",
        "        config.update({\r\n",
        "            'position': self.position,\r\n",
        "            'd_model': self.d_model,\r\n",
        "            \r\n",
        "        })\r\n",
        "        return config\r\n",
        "\r\n",
        "  def get_angles(self, position, i, d_model):\r\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\r\n",
        "    return position * angles\r\n",
        "\r\n",
        "  def positional_encoding(self, position, d_model):\r\n",
        "    angle_rads = self.get_angles(\r\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\r\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\r\n",
        "        d_model=d_model)\r\n",
        "    # apply sin to even index in the array\r\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\r\n",
        "    # apply cos to odd index in the array\r\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\r\n",
        "\r\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\r\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\r\n",
        "    return tf.cast(pos_encoding, tf.float32)\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLWfiexNpet"
      },
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n",
        "\r\n",
        "  attention = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention\")({\r\n",
        "          'query': inputs,\r\n",
        "          'key': inputs,\r\n",
        "          'value': inputs,\r\n",
        "          'mask': padding_mask\r\n",
        "      })\r\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\r\n",
        "  add_attention = tf.keras.layers.add([inputs,attention])\r\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\r\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n",
        "  add_attention = tf.keras.layers.add([attention,outputs])\r\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UPbuhNROoWK"
      },
      "source": [
        "def encoder(vocab_size,\r\n",
        "            num_layers,\r\n",
        "            units,\r\n",
        "            d_model,\r\n",
        "            num_heads,\r\n",
        "            dropout,\r\n",
        "            name=\"encoder\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\r\n",
        "\r\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n",
        "  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\r\n",
        "  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n",
        "\r\n",
        "  for i in range(num_layers):\r\n",
        "    outputs = encoder_layer(\r\n",
        "        units=units,\r\n",
        "        d_model=d_model,\r\n",
        "        num_heads=num_heads,\r\n",
        "        dropout=dropout,\r\n",
        "        name=\"encoder_layer_{}\".format(i),\r\n",
        "    )([outputs, padding_mask])\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9lSJLVaQQ7P"
      },
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\r\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\r\n",
        "  look_ahead_mask = tf.keras.Input(\r\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n",
        "\r\n",
        "  attention1 = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\r\n",
        "          'query': inputs,\r\n",
        "          'key': inputs,\r\n",
        "          'value': inputs,\r\n",
        "          'mask': look_ahead_mask\r\n",
        "      })\r\n",
        "  add_attention = tf.keras.layers.add([attention1,inputs])    \r\n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n",
        "\r\n",
        "  attention2 = MultiHeadAttention(\r\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\r\n",
        "          'query': attention1,\r\n",
        "          'key': enc_outputs,\r\n",
        "          'value': enc_outputs,\r\n",
        "          'mask': padding_mask\r\n",
        "      })\r\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\r\n",
        "  add_attention = tf.keras.layers.add([attention2,attention1])\r\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\r\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\r\n",
        "  add_attention = tf.keras.layers.add([outputs,attention2])\r\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n",
        "      outputs=outputs,\r\n",
        "      name=name)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RV6cuaROi1"
      },
      "source": [
        "def decoder(vocab_size,\r\n",
        "            num_layers,\r\n",
        "            units,\r\n",
        "            d_model,\r\n",
        "            num_heads,\r\n",
        "            dropout,\r\n",
        "            name='decoder'):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\r\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\r\n",
        "  look_ahead_mask = tf.keras.Input(\r\n",
        "      shape=(1, None, None), name='look_ahead_mask')\r\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\r\n",
        "  \r\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\r\n",
        "  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\r\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\r\n",
        "\r\n",
        "  for i in range(num_layers):\r\n",
        "    outputs = decoder_layer(\r\n",
        "        units=units,\r\n",
        "        d_model=d_model,\r\n",
        "        num_heads=num_heads,\r\n",
        "        dropout=dropout,\r\n",
        "        name='decoder_layer_{}'.format(i),\r\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\r\n",
        "\r\n",
        "  return tf.keras.Model(\r\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\r\n",
        "      outputs=outputs,\r\n",
        "      name=name)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qMl5RNPRkv6"
      },
      "source": [
        "def transformer(vocab_size,\r\n",
        "                num_layers,\r\n",
        "                units,\r\n",
        "                d_model,\r\n",
        "                num_heads,\r\n",
        "                dropout,\r\n",
        "                name=\"transformer\"):\r\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\r\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\r\n",
        "\r\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\r\n",
        "      create_padding_mask, output_shape=(1, 1, None),\r\n",
        "      name='enc_padding_mask')(inputs)\r\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\r\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\r\n",
        "      create_look_ahead_mask,\r\n",
        "      output_shape=(1, None, None),\r\n",
        "      name='look_ahead_mask')(dec_inputs)\r\n",
        "  # mask the encoder outputs for the 2nd attention block\r\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\r\n",
        "      create_padding_mask, output_shape=(1, 1, None),\r\n",
        "      name='dec_padding_mask')(inputs)\r\n",
        "\r\n",
        "  enc_outputs = encoder(\r\n",
        "      vocab_size=vocab_size,\r\n",
        "      num_layers=num_layers,\r\n",
        "      units=units,\r\n",
        "      d_model=d_model,\r\n",
        "      num_heads=num_heads,\r\n",
        "      dropout=dropout,\r\n",
        "  )(inputs=[inputs, enc_padding_mask])\r\n",
        "\r\n",
        "  dec_outputs = decoder(\r\n",
        "      vocab_size=vocab_size,\r\n",
        "      num_layers=num_layers,\r\n",
        "      units=units,\r\n",
        "      d_model=d_model,\r\n",
        "      num_heads=num_heads,\r\n",
        "      dropout=dropout,\r\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\r\n",
        "\r\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\r\n",
        "\r\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLzEQvsmRxGi"
      },
      "source": [
        "def loss_function(y_true, y_pred):\r\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n",
        "  \r\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\r\n",
        "\r\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\r\n",
        "  loss = tf.multiply(loss, mask)\r\n",
        "\r\n",
        "  return tf.reduce_mean(loss)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJbmTuF5R5x8"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\r\n",
        "\r\n",
        "  def __init__(self, d_model, warmup_steps=4000):\r\n",
        "    super(CustomSchedule, self).__init__()\r\n",
        "    \r\n",
        "    self.d_model = tf.constant(d_model,dtype=tf.float32)\r\n",
        "    self.warmup_steps = warmup_steps\r\n",
        "    \r\n",
        "  def get_config(self):\r\n",
        "        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\r\n",
        "    \r\n",
        "  def __call__(self, step):\r\n",
        "    arg1 = tf.math.rsqrt(step)\r\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\r\n",
        "\r\n",
        "    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58ALMw3XSIPp",
        "outputId": "bfeaf84a-9e49-42ef-a49d-633418731434"
      },
      "source": [
        "# clear backend\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "learning_rate = CustomSchedule(D_MODEL)\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(\r\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\r\n",
        "\r\n",
        "def accuracy(y_true, y_pred):\r\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\r\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\r\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\r\n",
        "\r\n",
        "# initialize and compile model within strategy scope\r\n",
        "with strategy.scope():\r\n",
        "  model = transformer(\r\n",
        "      vocab_size=VOCAB_SIZE,\r\n",
        "      num_layers=NUM_LAYERS,\r\n",
        "      units=UNITS,\r\n",
        "      d_model=D_MODEL,\r\n",
        "      num_heads=NUM_HEADS,\r\n",
        "      dropout=DROPOUT)\r\n",
        "\r\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 512)    13335040    inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Functional)            (None, None, 512)    15438336    dec_inputs[0][0]                 \n",
            "                                                                 encoder[0][0]                    \n",
            "                                                                 look_ahead_mask[0][0]            \n",
            "                                                                 dec_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, None, 19881)  10198953    decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 38,972,329\n",
            "Trainable params: 38,972,329\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        },
        "id": "twfj6NbSSawD",
        "outputId": "104da277-adda-40fe-ce21-8e44ae8c2ff2"
      },
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   2/2165 [..............................] - ETA: 4:08:22 - loss: 5.3605 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_train_batch_end` time: 0.1191s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_train_batch_end` time: 0.1191s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2165/2165 [==============================] - 244s 113ms/step - loss: nan - accuracy: 0.1165\n",
            "Epoch 2/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.1733\n",
            "Epoch 3/20\n",
            "2165/2165 [==============================] - 222s 103ms/step - loss: nan - accuracy: 0.1879\n",
            "Epoch 4/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.1973\n",
            "Epoch 5/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.2036\n",
            "Epoch 6/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.2083\n",
            "Epoch 7/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.2121\n",
            "Epoch 8/20\n",
            "2165/2165 [==============================] - 221s 102ms/step - loss: nan - accuracy: 0.2153\n",
            "Epoch 9/20\n",
            "2165/2165 [==============================] - 222s 102ms/step - loss: nan - accuracy: 0.2180\n",
            "Epoch 10/20\n",
            " 534/2165 [======>.......................] - ETA: 2:46 - loss: 1.6690 - accuracy: 0.2211"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-89cd9a1a0817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvKl9S45TXaa"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  sentence = tf.expand_dims(\r\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\r\n",
        "\r\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\r\n",
        "\r\n",
        "  for i in range(MAX_LENGTH):\r\n",
        "    predictions = model(inputs=[sentence, output], training=False)\r\n",
        "\r\n",
        "    # select the last word from the seq_len dimension\r\n",
        "    predictions = predictions[:, -1:, :]\r\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\r\n",
        "\r\n",
        "    # return the result if the predicted_id is equal to the end token\r\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\r\n",
        "      break\r\n",
        "\r\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\r\n",
        "    # as its input.\r\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\r\n",
        "\r\n",
        "  return tf.squeeze(output, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "def predict(sentence):\r\n",
        "  prediction = evaluate(sentence)\r\n",
        "\r\n",
        "  predicted_sentence = tokenizer.decode(\r\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\r\n",
        "\r\n",
        "  print('Input: {}'.format(sentence))\r\n",
        "  print('Output: {}'.format(predicted_sentence))\r\n",
        "\r\n",
        "  return predicted_sentence"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBs6WfxCtdN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f356b812-1843-4fb2-f7db-a30bcb4946cd"
      },
      "source": [
        "output = predict(\"What are the symptoms of flu?\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: What are the symptoms of flu?\n",
            "Output: Flu symptoms may include:  muscle aches ; pains, a fever above 100 degrees, headache, congestion, weakness, chills, increased sweating and coughing. If you suspect you have a flu or pneumonia, please see your doctor.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQCUyVMdTf5-",
        "outputId": "2128f115-c6a8-4bb4-bdf6-852abcc1181f"
      },
      "source": [
        "output = predict(\"What causes heartattack?\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: What causes heartattack?\n",
            "Output: The most common cause of heart attack is smoking, diabetes, high cholesterol, high blood pressure, high cholesterol, and smoking.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRkZ0HqAklVV",
        "outputId": "c78824b5-277f-426f-b436-9a9aae67c4c4"
      },
      "source": [
        "output = predict(\"What are different types of diabetes?\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: What are different types of diabetes?\n",
            "Output: Diabetes is a type of diabetes that is caused by a type of diabetes. It is a type of diabetes that is caused by a type of diabetes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4rDPSDckuec",
        "outputId": "d7e4866e-ba75-467e-adca-f9256dbd1f3c"
      },
      "source": [
        "output = predict(\"What causes hair loss?\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: What causes hair loss?\n",
            "Output: Hair loss can be caused by many different things. The most common is iron deficiency and thyroid disease. Other causes include thyroid disease, hormonal problems, and thyroid problems. See your doctor for a complete evaluation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK1ZUJMckywV",
        "outputId": "14dd1990-b5f0-4416-fef8-28360becc09f"
      },
      "source": [
        "output = predict(\"I am having nausea and headache. what should i do?\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: I am having nausea and headache. what should i do?\n",
            "Output: Nausea and headache are common symptoms of migraine headaches. Nausea and headache are common symptoms of migraine headaches. Nausea and headache are common symptoms of migraine headaches. See your doctor for a proper evaluation and treatment.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}